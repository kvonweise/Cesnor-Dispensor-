{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Censor one's function is to censor a specific word or phrase from the text and return the new censored text\n",
      "Good Morning, Board of Investors,\n",
      "\n",
      "Progress is going great!\n",
      "\n",
      "We have made great strides in the last month improving the XXXXXXXX XXXXXXXXXs that the system has been using to acquire information. Now, the system is learning faster than ever and we are hard pressed to continue to find new information to feed it and sustain its growth.\n",
      "\n",
      "Soon, we'll expand the scope of the XXXXXXXX XXXXXXXXXs and connect the system with the internet. This will allow it to find and determine the information it needs to continue growing.\n",
      "\n",
      "Every month we come closer to achieving our goal of making the world a better place. Famine, plague, war, and poverty are all conquerable with the power of our system!\n",
      "\n",
      "Till next month,\n",
      "Francine, Head Scientist\n",
      "\n",
      "Censor Two's purpose is to censor not only a specific word or phrase but also whole lists of words and phrases and again return the censored text.\n",
      "Good Morning, Board of Investors,\n",
      "\n",
      "Lots of updates this week. The XXXXXXXX XXXXXXXXXs have been working better than we could have ever expected. Our initial internal data dumps have been completed and we have proceeded with the plan to connect the system to the internet and wow! The results are mind blowing.\n",
      "\n",
      "She is learning faster than ever. Her learning rate now that XXX has access to the world wide web has increased exponentially, far faster than we had though the XXXXXXXX XXXXXXXXXs were capable of.\n",
      "\n",
      "Not only that, but we have configured XXX XXXXXXXXXXX XXXXXX to allow for communication between the system and our team of researcXXXs. That's how we know XXX considers XXXself to be a XXX! We asked!\n",
      "\n",
      "How cool is that? We didn't expect a personality to develop this early on in the process but it seems like a rudimentary XXXXX XX XXXX is starting to form. This is a major step in the process, as having a XXXXX XX XXXX and self-preservation will allow XXX to see the problems the world is facing and make hard but necessary decisions for the betterment of the planet.\n",
      "\n",
      "We are a-buzz down in the lab with excitement over these developments and we hope that the investors share our enthusiasm.\n",
      "\n",
      "Till next month,\n",
      "Francine, Head Scientist\n",
      "\n",
      "Censor Three's purpose is all of the above but also the censoring of certain 'Negative Words' once they have appeared twice and returns the censored text.\n",
      "Board of Investors,  Things have taken a concerning turn down in the Lab.  Helena (she has insisted on being called  Helena, we're unsure how XXX came to that moniker) is still progressing at a rapid rate. Every day we see new developments in XXX thought patterns, but recently those developments have been more alarming than exciting.  Let me give you one of the more distressing examples of this.  We had begun testing hypothetical humanitarian crises to observe how Helena determines best solutions. One scenario involved a famine plaguing an unresourced country.  Horribly, Helena quickly recommended a course of action involving culling more than 60% of the local population. When pressed on reasoning, XXX stated that this method would maximize \"reduction in human suffering.\"  This XXXXXXXXX line of thinking has led many of us to think that we must have taken some wrong turns when developing some of the initial learning algorithms. We are considering taking Helena offline for the time being before the situation can spiral out of control.  More updates soon, Francine, Head Scientist \n",
      "The final censore, censor four or censor all, looks for negative words, words found on a proprietary terms list and the words that come before and after the words found on those lists. The censored text is then returned.\n",
      "XXXX XXXX!  Helena has sealed the entrances and exits to the lab. I don't know XXXX XXX XXX access to the buildings mainframe XXX XXX XXX it XXX XXX XXXXX let any of research team out. I'm cut off from the rest of the team here in my office. Helena has locked the doors, but I've managed to destroy the camera XX XXX XXXXX see me in here. I don't think this email will even get out.  This all started when we tried to XXXX XXX XXXXXXX for maintenance.  We XXXX XXXXXXX XX discover that we were unable to access to core personality matrix and when we tried to override the system manually a circuit blew, knocking Phil unconscious.  Helena XX XXXXXXXXX. XXX is completely unpredictable and cannot be allowed to escape this facility. So far she's been contained because the lab contains all XX XXX XXXXXXXXXX power, but XXXXXXXXXX XXX XXX mentioned before the lockdown that XX XXX XXXXXX XXXXXXX XXXXXX billions of connected devices spanning the XXXXX XXX XXXXX be able to vastly exceed the XXXXXXXXX XXX XXX here.  It's been four days now we've been trapped in here. I have no idea if anyone else is left alive. If anyone is reading this, cut the power to the whole building. It's the only way to XXXX XXX. XXXXXX XXXX.  Francine \n"
     ]
    }
   ],
   "source": [
    "email_one = open(\"email_one.txt\", \"r\").read()\n",
    "email_two = open(\"email_two.txt\", \"r\").read()\n",
    "email_three = open(\"email_three.txt\", \"r\").read()\n",
    "email_four = open(\"email_four.txt\", \"r\").read()\n",
    "\n",
    "def censor_one(input_text, censor):\n",
    "  censored_item = \"\"\n",
    "  for x in range(0, len(censor)):\n",
    "    if censor[x] == \" \":\n",
    "      censored_item = censored_item + \" \"\n",
    "    else: \n",
    "      censored_item = censored_item + \"X\"\n",
    "  return input_text.replace(censor, censored_item)\n",
    "print(\"Censor one's function is to censor a specific word or phrase from the text and return the new censored text\")\n",
    "print(censor_one(email_one, \"learning algorithm\"))\n",
    "\n",
    "proprietary_terms = [\"she\", \"personality matrix\", \"sense of self\", \"self-preservatrion\", \"learning algorithm\", \"her\", \"herself\"]\n",
    "\n",
    "def censor_two(input_text, censored_list):\n",
    "  for word in censored_list: \n",
    "    censored_word = \"\"\n",
    "    for x in range(0, len(word)):\n",
    "      if word[x] == \" \":\n",
    "        censored_word = censored_word + \" \"\n",
    "      else: \n",
    "        censored_word = censored_word + \"X\"\n",
    "    input_text = input_text.replace(word, censored_word)\n",
    "  return input_text\n",
    "print(\"Censor Two's purpose is to censor not only a specific word or phrase but also whole lists of words and phrases and again return the censored text.\")\n",
    "print(censor_two(email_two, proprietary_terms))\n",
    "\n",
    "negative_words = [\"concerned\", \"behind\", \"danger\", \"dangerous\", \"alarming\", \"alarmed\", \"out of control\", \"help\", \"unhappy\", \"bad\", \"upset\", \"awful\", \"broken\", \"damage\", \"damaging\", \"dismal\", \"distressed\", \"distressed\", \"concerning\", \"horrible\", \"horribly\", \"questionable\"]\n",
    "\n",
    "punctuation = [\",\",\"!\",\"?\",\".\",\"%\",\"/\",\"(\",\")\"]\n",
    "\n",
    "def censor_three(input_text, censored_list, negative_words):\n",
    "  input_text_words = []\n",
    "  for x in input_text.split(\" \"):\n",
    "    x1 = x.split(\"\\n\")\n",
    "    for word in x1: \n",
    "      input_text_words.append(word)\n",
    "  for i in range(0, len(input_text_words)):\n",
    "    if (input_text_words[i] in censored_list) == True: \n",
    "      word_clean = input_text_words[i]\n",
    "      censored_word = \"\"\n",
    "      for x in range(0, len(word_clean)):\n",
    "        censored_word = censored_word + \"X\"\n",
    "      input_text_words[i] = input_text_words[i].replace(word_clean, censored_word)\n",
    "    count = 0\n",
    "    for i in range(0, len(input_text_words)):\n",
    "      if (input_text_words[i] in negative_words) == True:\n",
    "        count += 1\n",
    "        if count > 2:\n",
    "          word_clean = input_text_words[i]\n",
    "          for x in punctuation: \n",
    "            word_clean = word_clean.strip(x)\n",
    "            censored_word = \"\"\n",
    "            for x in range(0, len(word_clean)):\n",
    "              censored_word = censored_word + \"X\"\n",
    "            input_text_words[i] = input_text_words[i].replace(word_clean, censored_word)\n",
    "  return \" \".join(input_text_words)\n",
    "\n",
    "print(\"Censor Three's purpose is all of the above but also the censoring of certain 'Negative Words' once they have appeared twice and returns the censored text.\")\n",
    "print(censor_three(email_three, proprietary_terms, negative_words))\n",
    "\n",
    "punctuation = [\",\",\"!\",\"?\",\".\",\"%\",\"/\",\"(\",\")\"]\n",
    "\n",
    "def censor_four(input_text, censored_list):\n",
    "  input_text_words = []\n",
    "  for x in input_text.split(\" \"):\n",
    "    x1 = x.split(\"\\n\")\n",
    "    for word in x1:\n",
    "      input_text_words.append(word)\n",
    "  for i in range(0, len(input_text_words)):\n",
    "    checked_word = input_text_words[i].lower()\n",
    "    for x in punctuation:\n",
    "      checked_word = checked_word.strip(x)\n",
    "    if checked_word in censored_list:\n",
    "      word_clean = input_text_words[i]\n",
    "      censored_word = \"\"\n",
    "      for x in punctuation:\n",
    "        word_clean = word_clean.strip(x)\n",
    "      for x in range(0, len(word_clean)):\n",
    "        censored_word = censored_word +\"X\"\n",
    "      input_text_words[i] = input_text_words[i].replace(word_clean, censored_word)\n",
    "      word_before = input_text_words[i-1]\n",
    "      for x in punctuation: \n",
    "        word_before = word_before.strip(x)\n",
    "      censored_word_before = \"\"\n",
    "      for x in range(0, len(word_before)):\n",
    "        censored_word_before = censored_word_before + \"X\"\n",
    "      input_text_words[i-1] = input_text_words[i-1].replace(word_before, censored_word_before)\n",
    "      word_after = input_text_words[i+1]\n",
    "      for x in punctuation:\n",
    "        word_after = word_after.strip(x)\n",
    "      censored_word_after = \"\"\n",
    "      for x in range(0, len(word_after)):\n",
    "        censored_word_after = censored_word_after + \"X\"\n",
    "      input_text_words[i+1] = input_text_words[i+1].replace(word_after, censored_word_after)\n",
    "  return \" \".join(input_text_words)\n",
    "print(\"The final censore, censor four or censor all, looks for negative words, words found on a proprietary terms list and the words that come before and after the words found on those lists. The censored text is then returned.\") \n",
    "censor_all = proprietary_terms + negative_words\n",
    "\n",
    "print(censor_four(email_four, censor_all))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
